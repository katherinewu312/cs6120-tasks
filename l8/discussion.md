Group (@katherinewu312, @ngernest, @samuelbreckenridge)          
[(Code)](https://github.com/katherinewu312/cs6120-tasks/tree/main/l8)

We implemented LICM in LLVM. Our implementation follows roughly the high-level pseudocode mentioned in lecture, where for every instruction in the loop, we mark it as loop invariant iff for all its operands, either all their reaching definitions are outside the loop or there is exactly one definition and it is already marked as loop invariant. We then iterate this to convergence. After identifying all possible loop invariant instructions, we make sure to move them up to the preheader block.
(Instructions which are eligible for LICM under our pass include unary/binary operators, comparison instructions and `getelementptr`.)

The implementation was more challenging than we initially thought, mainly due to difficulties in navigating and understanding the LLVM docs. In the beginning, we were looking into using provided helper functions from LLVM such as `Loop::hasLoopInvariantOperands` and `Loop::makeLoopInvariant`. We had a preliminary implementation that called these methods, but we realized this essentially outsourced the work for us. We then decided to revamp our implementation so that we were actually implementing the specifics of the LICM pass ourselves, following the high-level pseudocode from lecture and checking explicitly when it is safe to move a loop-invariant instruction to the preheader.

Specifically, getting the pass manager to work was challenging. We learned that LLVM currently contains two pass managers, the legacy PM and the new PM. The optimization pipeline (aka the middle-end) uses the new PM, whereas the backend target-dependent code generation uses the legacy PM. We realized that to add a pass, we must match the pass type and the pass manager type: this was the underlying cause of an issue that arose for us. We were trying to reuse the pass manager from the skeleton-llvm-pass from lecture and ended up running into issues due to us directly adding a LoopPassManager pass type to a ModulePassManager pass manager type. Luckily, [this link](https://discourse.llvm.org/t/how-to-write-a-loop-pass-using-new-pass-manager/70240) was helpful in resolving the issue!

We also ran into an issue involving `load`s and `store`s, where our pass would keep 
running over because we weren't handling these instructions properly. To solve this issue, we first ran LLVM's `mem2reg` pass before running our LICM pass -- `mem2reg` converts memory references to register references, removing `load` and `store` instructions. 

We tested our implementation first on some handwritten test cases designed to cover some of the scenarios where we would expect LICM to kick in, as well as some corner cases where it shouldn't (e.g. the instruction both has side effects and does not dominate all exits). We were able to get these working and see our pass optimize some code when applied to the output of mem2reg. 

We tested our implementation on C benchmarks taken from the [Computer Language Benchmark Game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html)... We found that of these benchmarks our LICM pass only optimized n-body. It was hard to tell whether this was because there were not LICM opportunities in the other benchmarks, or because while getting our implementation to work we made it too restrictive in some cases. Testing the result of the optimizations for n-body yielded no appreciable speedup. We had a lot of trouble figuring out how to compile these benhmarks to compare an unoptimized version (except for the mem2reg pass) with an optimized version that ran only our pass on top of this. We spent a lot of time hacking with the LLVM opt command to get this to work. Although we were able to get embench running, we ultimately could not figure out a way to build the suite unoptimized with only the mem2reg pass (and our LICM pass for the optimized version) enabled so unfortunately do not have more substantive results to report. 

